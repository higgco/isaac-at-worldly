{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tier 1 Grouping Analysis\n",
    "\n",
    "## Setup Instructions\n",
    "\n",
    "### 1. Create Virtual Environment\n",
    "```bash\n",
    "# Create virtual environment\n",
    "python -m venv tier-1-venv\n",
    "\n",
    "# Activate virtual environment\n",
    "# On macOS/Linux:\n",
    "source tier-1-venv/bin/activate\n",
    "# On Windows:\n",
    "# tier-1-venv\\Scripts\\activate\n",
    "```\n",
    "\n",
    "### 2. Install Dependencies\n",
    "```bash\n",
    "# Make sure virtual environment is activated\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "### 3. Create .env File\n",
    "Create a `.env` file in the project root with your database credentials:\n",
    "\n",
    "```env\n",
    "DB_USER=your_username\n",
    "DB_PASSWORD=your_password\n",
    "DB_HOST=wg-data-rds.data.higg.org\n",
    "DB_PORT=5432\n",
    "DB_NAME=db_higg\n",
    "```\n",
    "\n",
    "**‚ö†Ô∏è Important:** Replace the placeholder values with your actual database credentials.\n",
    "\n",
    "### 4. Start Jupyter\n",
    "```bash\n",
    "# Make sure virtual environment is activated\n",
    "source tier-1-venv/bin/activate\n",
    "\n",
    "# Start Jupyter\n",
    "jupyter notebook\n",
    "# or\n",
    "jupyter lab\n",
    "```\n",
    "\n",
    "### 5. Select Kernel\n",
    "- Open this notebook\n",
    "- Select **\"Tier 1 Analysis\"** as your kernel\n",
    "- Run the cells in order\n",
    "\n",
    "## Security Notes\n",
    "- **Never commit** the `.env` file to version control\n",
    "- **Keep credentials secure** and don't share them\n",
    "- **Use different credentials** for different environments (dev/staging/prod)\n",
    "\n",
    "## Troubleshooting\n",
    "- **Connection issues**: Verify your database credentials in `.env`\n",
    "- **Kernel not found**: Make sure you've activated the virtual environment\n",
    "- **Package errors**: Run `pip install -r requirements.txt` again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Connected to: wg-data-rds.data.higg.org:5432/db_higg\n",
      "üìÅ SQL file to execute: queries/facility type and pc.sql\n",
      "‚úÖ Environment variables loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Setup: Import libraries, load environment variables, and configure SQL file\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine, text\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Configuration: SQL file to execute\n",
    "SQL_FILE = 'queries/facility type and pc.sql'  # Change this to run a different SQL file\n",
    "\n",
    "# Create connection string\n",
    "DB_USER = os.getenv('DB_USER')\n",
    "DB_PASSWORD = os.getenv('DB_PASSWORD')\n",
    "DB_HOST = os.getenv('DB_HOST')\n",
    "DB_PORT = os.getenv('DB_PORT')\n",
    "DB_NAME = os.getenv('DB_NAME')\n",
    "\n",
    "connection_string = f\"postgresql+psycopg2://{DB_USER}:{DB_PASSWORD}@{DB_HOST}:{DB_PORT}/{DB_NAME}\"\n",
    "\n",
    "print(f\"‚úÖ Connected to: {DB_HOST}:{DB_PORT}/{DB_NAME}\")\n",
    "print(f\"üìÅ SQL file to execute: {SQL_FILE}\")\n",
    "print(\"‚úÖ Environment variables loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Creating database engine...\n",
      "‚úÖ DATABASE CONNECTION SUCCESSFUL!\n",
      "Status: Connection successful!\n",
      "Connected at: 2025-09-10 15:29:07.599823+00:00\n"
     ]
    }
   ],
   "source": [
    "# Create database engine and test connection\n",
    "print(\"üîß Creating database engine...\")\n",
    "\n",
    "try:\n",
    "    # Create engine with optimized settings\n",
    "    engine = create_engine(\n",
    "        connection_string,\n",
    "        pool_pre_ping=True,\n",
    "        pool_recycle=300,\n",
    "        echo=False\n",
    "    )\n",
    "    \n",
    "    # Test connection\n",
    "    with engine.connect() as connection:\n",
    "        result = connection.execute(text(\"SELECT 'Connection successful!' as status, current_timestamp as time\"))\n",
    "        row = result.fetchone()\n",
    "        \n",
    "    print(\"‚úÖ DATABASE CONNECTION SUCCESSFUL!\")\n",
    "    print(f\"Status: {row[0]}\")\n",
    "    print(f\"Connected at: {row[1]}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(\"‚ùå DATABASE CONNECTION FAILED!\")\n",
    "    print(f\"Error: {e}\")\n",
    "    print(\"\\nüîß Check your .env file credentials\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ Loading and executing SQL file: queries/facility type and pc.sql\n",
      "‚úÖ SQL file loaded (1606 characters)\n",
      "‚úÖ QUERY EXECUTED SUCCESSFULLY!\n",
      "üìä Results: 5438 rows, 4 columns\n",
      "üìã Columns: ['assessment_id', 'finished_product_assembly_prod_vol_pcs', 'sipfacilityapparelpc', 'apparel_pc_count']\n"
     ]
    }
   ],
   "source": [
    "# Execute your SQL file\n",
    "print(f\"üìÅ Loading and executing SQL file: {SQL_FILE}\")\n",
    "\n",
    "try:\n",
    "    # Read SQL file using the configured variable\n",
    "    with open(SQL_FILE, 'r') as file:\n",
    "        sql_query = file.read()\n",
    "    \n",
    "    print(f\"‚úÖ SQL file loaded ({len(sql_query)} characters)\")\n",
    "    \n",
    "    # Execute query using manual method\n",
    "    with engine.connect() as connection:\n",
    "        result = connection.execute(text(sql_query))\n",
    "        rows = result.fetchall()\n",
    "        columns = result.keys()\n",
    "        \n",
    "    # Create DataFrame\n",
    "    df_results = pd.DataFrame(rows, columns=columns)\n",
    "    \n",
    "    print(\"‚úÖ QUERY EXECUTED SUCCESSFULLY!\")\n",
    "    print(f\"üìä Results: {df_results.shape[0]} rows, {df_results.shape[1]} columns\")\n",
    "    print(f\"üìã Columns: {list(df_results.columns)}\")\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(f\"‚ùå SQL FILE NOT FOUND: {SQL_FILE}\")\n",
    "    print(\"üîß Make sure the file exists in the current directory\")\n",
    "    print(\"üí° You can change the SQL_FILE variable in Cell 2 to point to a different file\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå QUERY EXECUTION FAILED: {e}\")\n",
    "    print(f\"\\nüîç SQL Query content from {SQL_FILE}:\")\n",
    "    print(\"=\" * 50)\n",
    "    print(sql_query)\n",
    "    print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Dataset Overview:\n",
      "   ‚Ä¢ Total rows: 5438\n",
      "   ‚Ä¢ Total columns: 4\n",
      "\n",
      "üìã Column Information:\n",
      "   ‚Ä¢ assessment_id: object (5438 non-null)\n",
      "   ‚Ä¢ finished_product_assembly_prod_vol_pcs: object (5438 non-null)\n",
      "   ‚Ä¢ sipfacilityapparelpc: object (5438 non-null)\n",
      "   ‚Ä¢ apparel_pc_count: int64 (5438 non-null)\n",
      "\n",
      "üìÑ First 10 rows:\n",
      "                                    assessment_id  \\\n",
      "0  femsurvey:fffff92a-914f-446f-812f-8141dbe416a6   \n",
      "1  femsurvey:ffff536a-d061-4fbd-84af-bfcaf59ac297   \n",
      "2  femsurvey:fff81b83-f145-404b-aeae-d0bb63b0fa1a   \n",
      "3  femsurvey:fff4757f-0b72-4f89-82cb-771a86980e0f   \n",
      "4  femsurvey:ffe917d7-0bf2-4469-af77-cba73a34e513   \n",
      "5  femsurvey:ffe53b8f-d79c-4480-a52f-92f026b318d2   \n",
      "6  femsurvey:ffba25e8-eaea-486e-9abf-6e362be0f88d   \n",
      "7  femsurvey:ffa679a1-848a-465e-92f3-9d518fbe7633   \n",
      "8  femsurvey:ffa0e74d-2f96-4117-b7ba-46680f7741f4   \n",
      "9  femsurvey:ff8205f1-281f-4d6f-8d69-72e447f694ca   \n",
      "\n",
      "  finished_product_assembly_prod_vol_pcs  \\\n",
      "0                                 400000   \n",
      "1                                 191551   \n",
      "2                                2251900   \n",
      "3                                3655942   \n",
      "4                                 337200   \n",
      "5                                6788626   \n",
      "6                                1737942   \n",
      "7                                2493679   \n",
      "8                                1781900   \n",
      "9                                1000000   \n",
      "\n",
      "                                sipfacilityapparelpc  apparel_pc_count  \n",
      "0          [Hosiery, Pants, Shirts, Skirts, T-shirt]                 5  \n",
      "1                           [Jackets, Pants, Shirts]                 3  \n",
      "2          [Dresses, Pants, Shirts, Skirts, T-shirt]                 5  \n",
      "3  [Baselayers, Hosiery, Pants, Shirts, T-shirt, ...                 6  \n",
      "4                                           [Shirts]                 1  \n",
      "5                [Dresses, Shirts, Skirts, Sweaters]                 4  \n",
      "6              [Dresses, Leggings & Tights, T-shirt]                 3  \n",
      "7  [Dresses, Pants, Shirts, Skirts, T-shirt, Unde...                 6  \n",
      "8                  [Dresses, Jackets, Pants, Shirts]                 4  \n",
      "9                           [Jackets, Pants, Shirts]                 3  \n",
      "\n",
      "üíæ To save results:\n",
      "df_results.to_csv('tier1_results.csv', index=False)\n"
     ]
    }
   ],
   "source": [
    "# Display and analyze results\n",
    "if 'df_results' in locals() and not df_results.empty:\n",
    "    print(\"üìä Dataset Overview:\")\n",
    "    print(f\"   ‚Ä¢ Total rows: {len(df_results)}\")\n",
    "    print(f\"   ‚Ä¢ Total columns: {len(df_results.columns)}\")\n",
    "    \n",
    "    print(\"\\nüìã Column Information:\")\n",
    "    for col in df_results.columns:\n",
    "        dtype = df_results[col].dtype\n",
    "        non_null = df_results[col].count()\n",
    "        print(f\"   ‚Ä¢ {col}: {dtype} ({non_null} non-null)\")\n",
    "    \n",
    "    print(\"\\nüìÑ First 10 rows:\")\n",
    "    print(df_results.head(10))\n",
    "    \n",
    "    print(\"\\nüíæ To save results:\")\n",
    "    print(\"df_results.to_csv('tier1_results.csv', index=False)\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå No results available. Run the previous cell first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ Loading PIC default product weights...\n",
      "‚úÖ PIC default product weights loaded successfully!\n",
      "üìä Weights data: 14 rows, 3 columns\n",
      "üìã Columns: ['FEM Apparel PC', 'PIC Product', 'Product Weight (kg)']\n",
      "\n",
      "üìÑ PIC Default Product Weights:\n",
      "       FEM Apparel PC  Product Weight (kg)\n",
      "0              Shirts             0.250000\n",
      "1             Dresses             0.374213\n",
      "2             Jackets             0.950000\n",
      "3               Pants             0.453592\n",
      "4              Skirts             0.290299\n",
      "5               Socks             0.400000\n",
      "6            Sweaters             0.550000\n",
      "7           Swimsuits             0.100000\n",
      "8          Baselayers             0.111130\n",
      "9             Hosiery             0.227000\n",
      "10  Leggings & Tights             0.227000\n",
      "11            Jerseys             0.150000\n",
      "12            T-shirt             0.150000\n",
      "13          Underwear             0.138346\n",
      "\n",
      "üîó Created weight mapping for 14 apparel categories:\n",
      "   ‚Ä¢ Shirts: 0.25 kg\n",
      "   ‚Ä¢ Dresses: 0.3742134 kg\n",
      "   ‚Ä¢ Jackets: 0.95 kg\n",
      "   ‚Ä¢ Pants: 0.453592 kg\n",
      "   ‚Ä¢ Skirts: 0.29029888 kg\n",
      "   ‚Ä¢ Socks: 0.4 kg\n",
      "   ‚Ä¢ Sweaters: 0.55 kg\n",
      "   ‚Ä¢ Swimsuits: 0.1 kg\n",
      "   ‚Ä¢ Baselayers: 0.11113004 kg\n",
      "   ‚Ä¢ Hosiery: 0.22700006 kg\n",
      "   ‚Ä¢ Leggings & Tights: 0.22700006 kg\n",
      "   ‚Ä¢ Jerseys: 0.15 kg\n",
      "   ‚Ä¢ T-shirt: 0.15 kg\n",
      "   ‚Ä¢ Underwear: 0.13834556 kg\n"
     ]
    }
   ],
   "source": [
    "# Load PIC default product weights for apparel categories\n",
    "print(\"üìÅ Loading PIC default product weights...\")\n",
    "\n",
    "try:\n",
    "    # Load the CSV file (it's actually tab-separated)\n",
    "    weights_df = pd.read_csv('PIC default product weights.csv', sep='\\t')\n",
    "    \n",
    "    print(\"‚úÖ PIC default product weights loaded successfully!\")\n",
    "    print(f\"üìä Weights data: {weights_df.shape[0]} rows, {weights_df.shape[1]} columns\")\n",
    "    print(f\"üìã Columns: {list(weights_df.columns)}\")\n",
    "    \n",
    "    # Display the weights data (only FEM Apparel PC and Product Weight columns)\n",
    "    print(\"\\nüìÑ PIC Default Product Weights:\")\n",
    "    display_df = weights_df[['FEM Apparel PC', 'Product Weight (kg)']]\n",
    "    print(display_df)\n",
    "    \n",
    "    # Create a dictionary mapping for easy lookup\n",
    "    apparel_weights = dict(zip(weights_df['FEM Apparel PC'], weights_df['Product Weight (kg)']))\n",
    "    \n",
    "    print(f\"\\nüîó Created weight mapping for {len(apparel_weights)} apparel categories:\")\n",
    "    for category, weight in apparel_weights.items():\n",
    "        print(f\"   ‚Ä¢ {category}: {weight} kg\")\n",
    "     \n",
    "except FileNotFoundError:\n",
    "    print(\"‚ùå PIC default product weights.csv file not found!\")\n",
    "    print(\"üîß Make sure the file exists in the current directory\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error loading weights file: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚öñÔ∏è Calculating assumed average product weights...\n",
      "üìä Calculating average weights for each assessment...\n",
      "‚úÖ Average weights calculated!\n",
      "üìä Summary statistics:\n",
      "   ‚Ä¢ Total assessments: 5438\n",
      "   ‚Ä¢ Assessments with valid weights: 5438\n",
      "   ‚Ä¢ Assessments with missing weights: 0\n",
      "   ‚Ä¢ Average weight across all assessments: 0.3776 kg\n",
      "   ‚Ä¢ Min weight: 0.1000 kg\n",
      "   ‚Ä¢ Max weight: 0.9500 kg\n",
      "   ‚Ä¢ Median weight: 0.3740 kg\n",
      "\n",
      "üì¶ Production Volume Statistics (in kg):\n",
      "   ‚Ä¢ Total estimated production volume: 162,656,150,094 kg\n",
      "   ‚Ä¢ Average production per assessment: 29,911,024 kg\n",
      "   ‚Ä¢ Median production per assessment: 678,729 kg\n",
      "   ‚Ä¢ Min production: 0 kg\n",
      "   ‚Ä¢ Max production: 120,932,688,000 kg\n",
      "\n",
      "üìÑ Sample results (first 10 rows):\n",
      "                                    assessment_id  \\\n",
      "0  femsurvey:fffff92a-914f-446f-812f-8141dbe416a6   \n",
      "1  femsurvey:ffff536a-d061-4fbd-84af-bfcaf59ac297   \n",
      "2  femsurvey:fff81b83-f145-404b-aeae-d0bb63b0fa1a   \n",
      "3  femsurvey:fff4757f-0b72-4f89-82cb-771a86980e0f   \n",
      "4  femsurvey:ffe917d7-0bf2-4469-af77-cba73a34e513   \n",
      "5  femsurvey:ffe53b8f-d79c-4480-a52f-92f026b318d2   \n",
      "6  femsurvey:ffba25e8-eaea-486e-9abf-6e362be0f88d   \n",
      "7  femsurvey:ffa679a1-848a-465e-92f3-9d518fbe7633   \n",
      "8  femsurvey:ffa0e74d-2f96-4117-b7ba-46680f7741f4   \n",
      "9  femsurvey:ff8205f1-281f-4d6f-8d69-72e447f694ca   \n",
      "\n",
      "                                sipfacilityapparelpc  apparel_pc_count  \\\n",
      "0          [Hosiery, Pants, Shirts, Skirts, T-shirt]                 5   \n",
      "1                           [Jackets, Pants, Shirts]                 3   \n",
      "2          [Dresses, Pants, Shirts, Skirts, T-shirt]                 5   \n",
      "3  [Baselayers, Hosiery, Pants, Shirts, T-shirt, ...                 6   \n",
      "4                                           [Shirts]                 1   \n",
      "5                [Dresses, Shirts, Skirts, Sweaters]                 4   \n",
      "6              [Dresses, Leggings & Tights, T-shirt]                 3   \n",
      "7  [Dresses, Pants, Shirts, Skirts, T-shirt, Unde...                 6   \n",
      "8                  [Dresses, Jackets, Pants, Shirts]                 4   \n",
      "9                           [Jackets, Pants, Shirts]                 3   \n",
      "\n",
      "  finished_product_assembly_prod_vol_pcs  assumed_avg_product_weight_kg  \\\n",
      "0                                 400000                       0.274178   \n",
      "1                                 191551                       0.551197   \n",
      "2                                2251900                       0.303621   \n",
      "3                                3655942                       0.221678   \n",
      "4                                 337200                       0.250000   \n",
      "5                                6788626                       0.366128   \n",
      "6                                1737942                       0.250404   \n",
      "7                                2493679                       0.276075   \n",
      "8                                1781900                       0.506951   \n",
      "9                                1000000                       0.551197   \n",
      "\n",
      "       weight_range_category  estimated_production_volume_kg  \n",
      "0         Light (0.2-0.3 kg)                    1.096713e+05  \n",
      "1  Medium-Heavy (0.5-0.6 kg)                    1.055824e+05  \n",
      "2  Medium-Light (0.3-0.4 kg)                    6.837238e+05  \n",
      "3         Light (0.2-0.3 kg)                    8.104417e+05  \n",
      "4         Light (0.2-0.3 kg)                    8.430000e+04  \n",
      "5  Medium-Light (0.3-0.4 kg)                    2.485507e+06  \n",
      "6         Light (0.2-0.3 kg)                    4.351885e+05  \n",
      "7         Light (0.2-0.3 kg)                    6.884424e+05  \n",
      "8  Medium-Heavy (0.5-0.6 kg)                    9.033366e+05  \n",
      "9  Medium-Heavy (0.5-0.6 kg)                    5.511973e+05  \n",
      "\n",
      "üìä Weight Range Distribution:\n",
      "   ‚Ä¢ Very Light (0-0.2 kg): 673 assessments (12.4%)\n",
      "   ‚Ä¢ Light (0.2-0.3 kg): 950 assessments (17.5%)\n",
      "   ‚Ä¢ Medium-Light (0.3-0.4 kg): 1408 assessments (25.9%)\n",
      "   ‚Ä¢ Medium (0.4-0.5 kg): 1417 assessments (26.1%)\n",
      "   ‚Ä¢ Medium-Heavy (0.5-0.6 kg): 658 assessments (12.1%)\n",
      "   ‚Ä¢ Heavy (0.6+ kg): 332 assessments (6.1%)\n",
      "   ‚Ä¢ Unknown: 0 assessments (0.0%)\n",
      "\n",
      "üíæ Results exported successfully!\n",
      "üìÅ File saved to: /Users/isaac.hopwood/Documents/tier1_analysis_results_20250910_102947.csv\n",
      "üìä Exported 5438 rows with 7 columns\n",
      "üìã Columns exported: ['assessment_id', 'finished_product_assembly_prod_vol_pcs', 'sipfacilityapparelpc', 'apparel_pc_count', 'assumed_avg_product_weight_kg', 'estimated_production_volume_kg', 'weight_range_category']\n"
     ]
    }
   ],
   "source": [
    "# Calculate assumed average product weight for each assessment\n",
    "print(\"‚öñÔ∏è Calculating assumed average product weights...\")\n",
    "\n",
    "import ast  # For safely evaluating string representations of lists\n",
    "\n",
    "def calculate_average_weight(apparel_pc_list, weights_dict):\n",
    "    \"\"\"\n",
    "    Calculate average weight for a list of apparel product categories\n",
    "    \n",
    "    Args:\n",
    "        apparel_pc_list: List of apparel categories (e.g., [\"Shirts\", \"Pants\"])\n",
    "        weights_dict: Dictionary mapping apparel categories to weights\n",
    "    \n",
    "    Returns:\n",
    "        Average weight in kg, or None if no valid categories found\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Handle both list and string inputs\n",
    "        if isinstance(apparel_pc_list, str):\n",
    "            # If it's a string, try to parse it as a list\n",
    "            apparel_categories = ast.literal_eval(apparel_pc_list)\n",
    "        else:\n",
    "            # If it's already a list, use it directly\n",
    "            apparel_categories = apparel_pc_list\n",
    "        \n",
    "        # Get weights for each category\n",
    "        weights = []\n",
    "        for category in apparel_categories:\n",
    "            if category in weights_dict:\n",
    "                weights.append(weights_dict[category])\n",
    "            else:\n",
    "                print(f\"‚ö†Ô∏è Warning: Category '{category}' not found in weights dictionary\")\n",
    "        \n",
    "        # Calculate average if we have valid weights\n",
    "        if weights:\n",
    "            return sum(weights) / len(weights)\n",
    "        else:\n",
    "            return None\n",
    "            \n",
    "    except (ValueError, SyntaxError) as e:\n",
    "        print(f\"‚ö†Ô∏è Warning: Could not parse apparel categories: {apparel_pc_list}\")\n",
    "        return None\n",
    "\n",
    "# Apply the function to calculate average weights\n",
    "if 'df_results' in locals() and not df_results.empty:\n",
    "    print(\"üìä Calculating average weights for each assessment...\")\n",
    "    \n",
    "    # Calculate average weights\n",
    "    df_results['assumed_avg_product_weight_kg'] = df_results['sipfacilityapparelpc'].apply(\n",
    "        lambda x: calculate_average_weight(x, apparel_weights)\n",
    "    )\n",
    "    \n",
    "    # Convert production volume from pieces to kg using assumed average weight\n",
    "    # Convert decimal values to float to avoid type mismatch\n",
    "    df_results['estimated_production_volume_kg'] = (\n",
    "        df_results['finished_product_assembly_prod_vol_pcs'].astype(float) * \n",
    "        df_results['assumed_avg_product_weight_kg']\n",
    "    )\n",
    "    \n",
    "    # Add weight range category for each assessment\n",
    "    def categorize_weight_range(weight):\n",
    "        \"\"\"Categorize weight into predefined ranges\"\"\"\n",
    "        if pd.isna(weight):\n",
    "            return \"Unknown\"\n",
    "        elif 0 <= weight < 0.2:\n",
    "            return \"Very Light (0-0.2 kg)\"\n",
    "        elif 0.2 <= weight < 0.3:\n",
    "            return \"Light (0.2-0.3 kg)\"\n",
    "        elif 0.3 <= weight < 0.4:\n",
    "            return \"Medium-Light (0.3-0.4 kg)\"\n",
    "        elif 0.4 <= weight < 0.5:\n",
    "            return \"Medium (0.4-0.5 kg)\"\n",
    "        elif 0.5 <= weight < 0.6:\n",
    "            return \"Medium-Heavy (0.5-0.6 kg)\"\n",
    "        elif weight >= 0.6:\n",
    "            return \"Heavy (0.6+ kg)\"\n",
    "        else:\n",
    "            return \"Unknown\"\n",
    "    \n",
    "    df_results['weight_range_category'] = df_results['assumed_avg_product_weight_kg'].apply(categorize_weight_range)\n",
    "    \n",
    "    # Display summary statistics\n",
    "    valid_weights = df_results['assumed_avg_product_weight_kg'].dropna()\n",
    "    \n",
    "    print(f\"‚úÖ Average weights calculated!\")\n",
    "    print(f\"üìä Summary statistics:\")\n",
    "    print(f\"   ‚Ä¢ Total assessments: {len(df_results)}\")\n",
    "    print(f\"   ‚Ä¢ Assessments with valid weights: {len(valid_weights)}\")\n",
    "    print(f\"   ‚Ä¢ Assessments with missing weights: {len(df_results) - len(valid_weights)}\")\n",
    "    \n",
    "    if len(valid_weights) > 0:\n",
    "        print(f\"   ‚Ä¢ Average weight across all assessments: {valid_weights.mean():.4f} kg\")\n",
    "        print(f\"   ‚Ä¢ Min weight: {valid_weights.min():.4f} kg\")\n",
    "        print(f\"   ‚Ä¢ Max weight: {valid_weights.max():.4f} kg\")\n",
    "        print(f\"   ‚Ä¢ Median weight: {valid_weights.median():.4f} kg\")\n",
    "    \n",
    "    # Production volume statistics\n",
    "    valid_production_kg = df_results['estimated_production_volume_kg'].dropna()\n",
    "    if len(valid_production_kg) > 0:\n",
    "        print(f\"\\nüì¶ Production Volume Statistics (in kg):\")\n",
    "        print(f\"   ‚Ä¢ Total estimated production volume: {valid_production_kg.sum():,.0f} kg\")\n",
    "        print(f\"   ‚Ä¢ Average production per assessment: {valid_production_kg.mean():,.0f} kg\")\n",
    "        print(f\"   ‚Ä¢ Median production per assessment: {valid_production_kg.median():,.0f} kg\")\n",
    "        print(f\"   ‚Ä¢ Min production: {valid_production_kg.min():,.0f} kg\")\n",
    "        print(f\"   ‚Ä¢ Max production: {valid_production_kg.max():,.0f} kg\")\n",
    "    \n",
    "    # Show some examples\n",
    "    print(f\"\\nüìÑ Sample results (first 10 rows):\")\n",
    "    sample_cols = ['assessment_id', 'sipfacilityapparelpc', 'apparel_pc_count', \n",
    "                   'finished_product_assembly_prod_vol_pcs', 'assumed_avg_product_weight_kg', \n",
    "                   'weight_range_category', 'estimated_production_volume_kg']\n",
    "    print(df_results[sample_cols].head(10))\n",
    "    \n",
    "    # Show weight distribution using the new category column\n",
    "    print(f\"\\nüìä Weight Range Distribution:\")\n",
    "    weight_category_counts = df_results['weight_range_category'].value_counts()\n",
    "    total_assessments = len(df_results)\n",
    "    \n",
    "    for category in [\"Very Light (0-0.2 kg)\", \"Light (0.2-0.3 kg)\", \"Medium-Light (0.3-0.4 kg)\", \n",
    "                     \"Medium (0.4-0.5 kg)\", \"Medium-Heavy (0.5-0.6 kg)\", \"Heavy (0.6+ kg)\", \"Unknown\"]:\n",
    "        count = weight_category_counts.get(category, 0)\n",
    "        pct = (count / total_assessments) * 100\n",
    "        print(f\"   ‚Ä¢ {category}: {count} assessments ({pct:.1f}%)\")\n",
    "    \n",
    "    # Export results to CSV in Documents folder\n",
    "    import os\n",
    "    from datetime import datetime\n",
    "    \n",
    "    # Create filename with timestamp\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    filename = f\"tier1_analysis_results_{timestamp}.csv\"\n",
    "    \n",
    "    # Get Documents folder path\n",
    "    documents_path = os.path.expanduser(\"~/Documents\")\n",
    "    filepath = os.path.join(documents_path, filename)\n",
    "    \n",
    "    try:\n",
    "        # Export the DataFrame with all columns\n",
    "        df_results.to_csv(filepath, index=False)\n",
    "        print(f\"\\nüíæ Results exported successfully!\")\n",
    "        print(f\"üìÅ File saved to: {filepath}\")\n",
    "        print(f\"üìä Exported {len(df_results)} rows with {len(df_results.columns)} columns\")\n",
    "        print(f\"üìã Columns exported: {list(df_results.columns)}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå Export failed: {e}\")\n",
    "        print(\"üí° Trying alternative export to current directory...\")\n",
    "        try:\n",
    "            # Fallback to current directory\n",
    "            fallback_path = f\"tier1_analysis_results_{timestamp}.csv\"\n",
    "            df_results.to_csv(fallback_path, index=False)\n",
    "            print(f\"‚úÖ Fallback export successful: {fallback_path}\")\n",
    "        except Exception as e2:\n",
    "            print(f\"‚ùå Fallback export also failed: {e2}\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå No results data available. Run the previous cells first to load the data.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tier-1-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
